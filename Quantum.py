# -*- coding: utf-8 -*-
"""thanushree.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ht8BWZ7rKLTaPP2HXJx8OgGzVmyEwT-a
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Dataset root (your folder)
DATA_DIR = "/content/drive/MyDrive/MarineDebris"
print("✅ Dataset root:", DATA_DIR)

import os
import glob
import random
import shutil

# ✅ Define dataset root (your Drive path!)
DATA_DIR = "/content/drive/MyDrive/MarineDebris"

# Collect all image paths from train/valid/test
all_images = glob.glob(os.path.join(DATA_DIR, "train", "**", "*.jpg"), recursive=True)
all_images += glob.glob(os.path.join(DATA_DIR, "train", "**", "*.png"), recursive=True)
all_images += glob.glob(os.path.join(DATA_DIR, "valid", "**", "*.jpg"), recursive=True)
all_images += glob.glob(os.path.join(DATA_DIR, "valid", "**", "*.png"), recursive=True)
all_images += glob.glob(os.path.join(DATA_DIR, "test", "**", "*.jpg"), recursive=True)
all_images += glob.glob(os.path.join(DATA_DIR, "test", "**", "*.png"), recursive=True)

print("Total images found:", len(all_images))

# ✅ Limit to 3000 samples (images + labels)
random.seed(42)
all_images = random.sample(all_images, min(3000, len(all_images)))

# ✅ Create new dataset folder
LIMITED_DIR = "/content/MarineDebris_3k"
os.makedirs(LIMITED_DIR, exist_ok=True)

for split in ["train", "valid", "test"]:
    os.makedirs(os.path.join(LIMITED_DIR, split, "images"), exist_ok=True)
    os.makedirs(os.path.join(LIMITED_DIR, split, "labels"), exist_ok=True)

# ✅ Split: 75% train, 15% val, 15% test
train_cut = int(0.75 * len(all_images))
val_cut   = int(0.90 * len(all_images))

train_files = all_images[:train_cut]
val_files   = all_images[train_cut:val_cut]
test_files  = all_images[val_cut:]

# ✅ Copy function
def copy_files(file_list, split):
    for img_path in file_list:
        lbl_path = img_path.replace("images", "labels").rsplit(".", 1)[0] + ".txt"
        shutil.copy(img_path, os.path.join(LIMITED_DIR, split, "images"))
        if os.path.exists(lbl_path):
            shutil.copy(lbl_path, os.path.join(LIMITED_DIR, split, "labels"))

copy_files(train_files, "train")
copy_files(val_files, "valid")
copy_files(test_files, "test")

print("✅ Train:", len(train_files), "Val:", len(val_files), "Test:", len(test_files))

import os

# ✅ Ensure LIMITED_DIR is defined (if Cell 2 already ran, this will be reused)
LIMITED_DIR = "/content/MarineDebris_3k"

# ✅ Create dataset.yaml file for YOLO/RT-DETR
yaml_content = f"""
path: {LIMITED_DIR}
train: train/images
val: valid/images
test: test/images

names:
  0: class0
  1: class1
  2: class2
  3: class3
"""

yaml_path = os.path.join(LIMITED_DIR, "dataset.yaml")
with open(yaml_path, "w") as f:
    f.write(yaml_content)

print(f"✅ dataset.yaml created at {yaml_path}")

# Commented out IPython magic to ensure Python compatibility.
# ✅ Install dependencies
!pip install ultralytics==8.2.50 torch torchvision torchaudio timm transformers --quiet
!pip install numpy==1.26.4 --quiet

# ✅ Install TorchQuantum from GitHub
!git clone https://github.com/mit-han-lab/torchquantum.git
# %cd torchquantum
!pip install -e .
# %cd /content

# ✅ Imports
import torch
import torch.nn as nn
from torchvision import models
import torchquantum as tq
from ultralytics import YOLO

class QuantumResNetBackbone(nn.Module):
    def __init__(self, n_qubits=8):
        super().__init__()
        self.resnet = models.resnet50(pretrained=True)
        self.resnet.fc = nn.Identity()

        self.q_device = tq.QuantumDevice(n_wires=n_qubits)
        self.encoder = tq.GeneralEncoder(tq.encoder_op_list(n_qubits))
        self.q_layer = tq.RandomLayer(n_wires=n_qubits, n_ops=40)

        self.fc = nn.Linear(n_qubits, 2048)

    def forward(self, x):
        x = self.resnet(x)
        q_in = x[:, :self.q_device.n_wires]
        self.encoder(self.q_device, q_in)
        self.q_layer(self.q_device)
        q_out = self.q_device.get_states_1d().real
        q_out = self.fc(q_out)
        return x + q_out

# Install the latest version of the ultralytics library
!pip install --upgrade ultralytics

# Import necessary libraries
import torch
from ultralytics import YOLO

# Determine the device to use (GPU if available, else CPU)
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Running on: {device}")

# Load the YOLOv8 model using the official model name
model = YOLO("yolov8n")  # This will automatically download the model weights
model.model.to(device)
print("✅ YOLOv8 pre-trained model loaded successfully")

# ---------------- Step 0: Set device ----------------
import torch
device = 0 if torch.cuda.is_available() else "cpu"
print(f"Running on device: {device}")

# ---------------- Step 1: Load YOLOv8 pre-trained model ----------------
# ⚡ Important: use model name, NOT local .pt path (avoids UnpicklingError)
from ultralytics import YOLO

yolo_model = YOLO("yolov8n")  # small pre-trained YOLOv8, downloads automatically
print("✅ YOLOv8 pre-trained model loaded successfully")

# ---------------- Step 2: Dataset YAML path ----------------
dataset_yaml = "/content/MarineDebris_3k/dataset.yaml"

# ---------------- Step 3: Train YOLOv8 safely ----------------
# Use correct argument names: lr0 (initial LR), lrf (final LR factor)
yolo_model.train(
    data=dataset_yaml,
    epochs=100,       # Increase for better accuracy
    batch=16,        # Adjust to your GPU memory
    imgsz=640,
    optimizer="SGD",
    lr0=0.001,       # Initial learning rate
    lrf=0.01,        # Final LR factor
    device=device,   # GPU or CPU
    verbose=True
)

# ---------------- Step 4: Evaluate on validation set ----------------
metrics = yolo_model.val()  # computes mAP, precision, recall
print("✅ Evaluation results:")
print(metrics)

# ---------------- Step 5: Save trained model ----------------
trained_model_path = "/content/MarineDebris_3k/yolov8n_trained.pt"
yolo_model.save(trained_model_path)
print(f"✅ Trained model saved at: {trained_model_path}")

from ultralytics import YOLO

# Load trained YOLOv8 model
trained_model_path = "/content/MarineDebris_3k/yolov8n_trained.pt"
model = YOLO(trained_model_path)

# Evaluate on validation set
dataset_yaml = "/content/MarineDebris_3k/dataset.yaml"
results = model.val(data=dataset_yaml)

# Print only the accuracy (mAP50)
print(f"✅ Accuracy (mAP50): {results.box.map50:.4f}")